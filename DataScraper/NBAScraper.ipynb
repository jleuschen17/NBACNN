{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#package installs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def statScraper(name, year, playerindex, team_id):\n",
    "    index = int(playerindex)\n",
    "    for x in range(2):\n",
    "        url, advanced = urlConvertor(name, year, playerindex, x)\n",
    "        print(url)\n",
    "        try:\n",
    "            result = requests.get(url)\n",
    "            print(result.status_code)\n",
    "            src = result.content\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "            table = soup.find('table', {'class': 'row_summable'})\n",
    "            trs = table.find_all('tr')\n",
    "            rows = []\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                row = [td.text.replace('\\n', '').strip() for td in tds]\n",
    "                rows.append(row)\n",
    "            if x == 0:\n",
    "                columns = ['G', 'Date', 'Age', 'Tm', 'Location', 'Opp',\n",
    "                           'GS', 'Active', 'MP', 'FG', 'FGA', 'FG%',\n",
    "                           '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "                           'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "                           'PTS', 'GmSc', '+/-']\n",
    "                df = pd.DataFrame(rows, columns=columns)\n",
    "                df = df[df['Tm'] == team_id]\n",
    "                if len(df) == 0:\n",
    "                    index += 1\n",
    "                    newindex = '0' + str(index)\n",
    "                    statScraper(name, year, newindex, team_id)\n",
    "                result.close()\n",
    "                df['PlayerID'] = name[2]\n",
    "            elif x == 1:\n",
    "                columns = ['G', 'Date', 'Age', 'Tm', 'Location', 'Opp', 'GS',\n",
    "                           'Active', 'MP', 'TS%', 'eFG%', 'ORB%', 'DRB%',\n",
    "                           'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%',\n",
    "                           'USG%', 'ORtg', 'DRtg', 'GmSc', 'BPM']\n",
    "                df2 = pd.DataFrame(rows, columns=columns)\n",
    "                df2 = df2[df2['Tm'] == team_id]\n",
    "                if len(df2) == 0:\n",
    "                    index += 1\n",
    "                    newindex = '0' + str(index)\n",
    "                    statScraper(name, year, newindex, team_id)\n",
    "                result.close()\n",
    "                df2 = df2.drop(df2.columns[[0, 2, 3, 4, 5, 6, 7, 8, -2]], axis=1)\n",
    "        except:\n",
    "            print('Error Scraping' ,index)\n",
    "            index+=1\n",
    "            if index > 4:\n",
    "                print('Stat scraping failed for:', name[0], name[1])\n",
    "                print(url)\n",
    "                return None\n",
    "            newindex = '0' + str(index)\n",
    "            statScraper(name, year, newindex, team_id)\n",
    "    statdf = pd.merge(df, df2,how='outer', on='Date')\n",
    "    statdf.insert(0, 'Name', name[1] + ', ' + name[0])\n",
    "    print('Successfully Scraped:', name[0], name[1])\n",
    "    return statdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def urlConvertor(name, year, playerindex, advanced: bool):\n",
    "    lname = name[1]\n",
    "    fname = name[0]\n",
    "    lnamelist = list(lname)\n",
    "    linitial = lnamelist[0]\n",
    "    fnamelist = list(fname)\n",
    "    lname5 = ''\n",
    "    for x in range(5):\n",
    "        try:\n",
    "            lname5 += lnamelist[x]\n",
    "        except:\n",
    "            break\n",
    "    f2i = fnamelist[0] + fnamelist[1]\n",
    "    if advanced == False:\n",
    "        url = f'https://www.basketball-reference.com/players/{linitial}/{lname5}{f2i}{playerindex}/gamelog/{year}/'\n",
    "    else:\n",
    "        url = f'https://www.basketball-reference.com/players/{linitial}/{lname5}{f2i}{playerindex}/gamelog-advanced/{year}/'\n",
    "    return url, advanced\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def rosterScraper(TeamID, year, id_number):\n",
    "    url = f\"https://www.basketball-reference.com/teams/{TeamID}/{year}.html\"\n",
    "    result = requests.get(url)\n",
    "    try:\n",
    "        src = result.content\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        table = soup.find('table', {'class': 'sortable'})\n",
    "        names = []\n",
    "        trs = table.find_all('tr')\n",
    "        rows = []\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                td = tr.find('td', {'data-stat': 'player'})\n",
    "                a_tag = td.find('a')\n",
    "                name = a_tag.get_text()\n",
    "                name = unidecode.unidecode(name)\n",
    "                name = re.sub(r'[^\\w\\s]','',name)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                pass\n",
    "        for x in range(len(names)):\n",
    "            names[x] = names[x].split()\n",
    "            names[x].append(id_number)\n",
    "            id_number += 1\n",
    "        print(TeamID,\"roster successfully parsed\")\n",
    "        return names\n",
    "    except:\n",
    "        return False\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def teamFinder(year):\n",
    "    team_id = 101\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
    "    result = requests.get(url)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    table = soup.find('table', {'class': 'stats_table sortable', 'data-cols-to-freeze': ',2', 'id': 'per_game-team'})\n",
    "    teams = []\n",
    "    ids = {}\n",
    "    trs = table.find_all('tr')\n",
    "    x = 0\n",
    "    for tr in trs[1:]:\n",
    "        #print(tr.prettify())\n",
    "        try:\n",
    "            td = tr.find('td', {'data-stat': 'team', 'class': 'left'})\n",
    "            a_tag = td.find('a')\n",
    "            team = a_tag.get_text()\n",
    "            teams.append(team)\n",
    "            link = a_tag.attrs['href']\n",
    "            link = list(link)\n",
    "            acronym = link[7] + link[8] + link[9]\n",
    "            ids[teams[x]] = []\n",
    "            ids[teams[x]].append(acronym)\n",
    "            x+=1\n",
    "        except:\n",
    "            pass\n",
    "    for x in range(len(teams)):\n",
    "        ids[teams[x]].append(team_id)\n",
    "        team_id+=1\n",
    "    return teams, ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def leagueRosters(year):\n",
    "    teamrosters = {}\n",
    "    id_number = 1001\n",
    "    teams, team_ids = teamFinder(year)\n",
    "    for team in teams:\n",
    "        teamrosters[team] = rosterScraper(team_ids[team][0], year, id_number)\n",
    "        id_number+=len(teamrosters[team])\n",
    "    return teamrosters, team_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def teamRoster(team, year):\n",
    "    roster = []\n",
    "    id_number = 1001\n",
    "    teams, team_ids = teamFinder(year)\n",
    "    roster = rosterScraper(team_ids[team][0], year, id_number)\n",
    "    return roster, team_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def playerScraper(name, team, year):\n",
    "    name = name.split()\n",
    "    name.append('1001')\n",
    "    teams, ids = teamFinder(year)\n",
    "    team_id = ids[team][0]\n",
    "    df = statScraper(name, year, '01', team_id)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def teamScraper(team, year):\n",
    "    roster, team_ids = teamRoster(team, year)\n",
    "    for x in range(len(roster)):\n",
    "        try:\n",
    "            if x == 0:\n",
    "                player = roster[x]\n",
    "                df = statScraper(player, year, '01', team_ids[team][0])\n",
    "            else:\n",
    "                player = roster[x]\n",
    "                df = df.append(statScraper(player, year, '01', team_ids[team][0]))\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def leagueScraper(year):\n",
    "    rosters, team_ids = leagueRosters(year)\n",
    "    y = 0\n",
    "    for team in rosters:\n",
    "        for x in range(len(rosters[team])):\n",
    "            try:\n",
    "                if x == 0 and y == 0:\n",
    "                    player = rosters[team][x]\n",
    "                    print(player)\n",
    "                    df = statScraper(player, year, '01', team_ids[team][0])\n",
    "                else:\n",
    "                    player = rosters[team][x]\n",
    "                    df = df.append(statScraper(player, year, '01', team_ids[team][0]))\n",
    "            except:\n",
    "                pass\n",
    "        y+=1\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def save_df(df, title, path):\n",
    "    df.to_csv(rf'{path}\\{title}.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL roster successfully parsed\n",
      "https://www.basketball-reference.com/players/B/BazemKe01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/B/BazemKe01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Kent Bazemore\n",
      "https://www.basketball-reference.com/players/H/HardaTi01/gamelog/2016/\n",
      "200\n",
      "Error Scraping 1\n",
      "https://www.basketball-reference.com/players/H/HardaTi02/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HardaTi02/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Tim Hardaway\n",
      "https://www.basketball-reference.com/players/H/HardaTi01/gamelog-advanced/2016/\n",
      "200\n",
      "Error Scraping 2\n",
      "https://www.basketball-reference.com/players/H/HardaTi03/gamelog/2016/\n",
      "200\n",
      "Error Scraping 3\n",
      "https://www.basketball-reference.com/players/H/HardaTi04/gamelog/2016/\n",
      "200\n",
      "Error Scraping 4\n",
      "Stat scraping failed for: Tim Hardaway\n",
      "https://www.basketball-reference.com/players/H/HardaTi04/gamelog/2016/\n",
      "https://www.basketball-reference.com/players/H/HardaTi03/gamelog-advanced/2016/\n",
      "200\n",
      "Error Scraping 4\n",
      "Stat scraping failed for: Tim Hardaway\n",
      "https://www.basketball-reference.com/players/H/HardaTi03/gamelog-advanced/2016/\n",
      "https://www.basketball-reference.com/players/H/HinriKi01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HinriKi01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Kirk Hinrich\n",
      "https://www.basketball-reference.com/players/H/HolidJu01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HolidJu01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Justin Holiday\n",
      "https://www.basketball-reference.com/players/H/HorfoAl01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HorfoAl01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Al Horford\n",
      "https://www.basketball-reference.com/players/H/HumphKr01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HumphKr01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Kris Humphries\n",
      "https://www.basketball-reference.com/players/K/KorveKy01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/K/KorveKy01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Kyle Korver\n",
      "https://www.basketball-reference.com/players/M/MackSh01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/M/MackSh01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Shelvin Mack\n",
      "https://www.basketball-reference.com/players/M/MillsPa01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/M/MillsPa01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Paul Millsap\n",
      "https://www.basketball-reference.com/players/M/MuscaMi01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/M/MuscaMi01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Mike Muscala\n",
      "https://www.basketball-reference.com/players/P/PatteLa01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/P/PatteLa01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Lamar Patterson\n",
      "https://www.basketball-reference.com/players/S/SchroDe01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/S/SchroDe01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Dennis Schroder\n",
      "https://www.basketball-reference.com/players/S/ScottMi01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/S/ScottMi01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Mike Scott\n",
      "https://www.basketball-reference.com/players/S/SefolTh01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/S/SefolTh01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Thabo Sefolosha\n",
      "https://www.basketball-reference.com/players/S/SplitTi01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/S/SplitTi01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Tiago Splitter\n",
      "https://www.basketball-reference.com/players/T/TavarEd01/gamelog/2016/\n",
      "200\n",
      "Error Scraping 1\n",
      "https://www.basketball-reference.com/players/T/TavarEd02/gamelog/2016/\n",
      "200\n",
      "Error Scraping 2\n",
      "https://www.basketball-reference.com/players/T/TavarEd03/gamelog/2016/\n",
      "200\n",
      "Error Scraping 3\n",
      "https://www.basketball-reference.com/players/T/TavarEd04/gamelog/2016/\n",
      "200\n",
      "Error Scraping 4\n",
      "Stat scraping failed for: Edy Tavares\n",
      "https://www.basketball-reference.com/players/T/TavarEd04/gamelog/2016/\n",
      "https://www.basketball-reference.com/players/T/TavarEd03/gamelog-advanced/2016/\n",
      "200\n",
      "Error Scraping 4\n",
      "Stat scraping failed for: Edy Tavares\n",
      "https://www.basketball-reference.com/players/T/TavarEd03/gamelog-advanced/2016/\n",
      "https://www.basketball-reference.com/players/T/TavarEd02/gamelog-advanced/2016/\n",
      "200\n",
      "Error Scraping 3\n",
      "https://www.basketball-reference.com/players/T/TavarEd04/gamelog/2016/\n",
      "200\n",
      "Error Scraping 4\n",
      "Stat scraping failed for: Edy Tavares\n",
      "https://www.basketball-reference.com/players/T/TavarEd04/gamelog/2016/\n",
      "https://www.basketball-reference.com/players/T/TeaguJe01/gamelog/2016/\n",
      "200\n",
      "https://www.basketball-reference.com/players/T/TeaguJe01/gamelog-advanced/2016/\n",
      "200\n",
      "Successfully Scraped: Jeff Teague\n"
     ]
    }
   ],
   "source": [
    "save_df(teamScraper('Atlanta Hawks', '2016'), 'Hawks2016', r\"C:\\Users\\jleus\\OneDrive\\Documents\\CSVS\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}