{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#package installs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def statScraper(name, year, playerindex, team_id):\n",
    "    index = int(playerindex)\n",
    "    for x in range(2):\n",
    "        url, advanced = urlConvertor(name, year, playerindex, x)\n",
    "        print(url)\n",
    "        try:\n",
    "            result = requests.get(url)\n",
    "            print(result.status_code)\n",
    "            src = result.content\n",
    "            soup = BeautifulSoup(src, 'lxml')\n",
    "            table = soup.find('table', {'class': 'row_summable'})\n",
    "            trs = table.find_all('tr')\n",
    "            rows = []\n",
    "            for tr in trs:\n",
    "                tds = tr.find_all('td')\n",
    "                row = [td.text.replace('\\n', '').strip() for td in tds]\n",
    "                rows.append(row)\n",
    "            if x == 0:\n",
    "                columns = ['G', 'Date', 'Age', 'Tm', 'Location', 'Opp',\n",
    "                           'GS', 'Active', 'MP', 'FG', 'FGA', 'FG%',\n",
    "                           '3P', '3PA', '3P%', 'FT', 'FTA', 'FT%', 'ORB',\n",
    "                           'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF',\n",
    "                           'PTS', 'GmSc', '+/-']\n",
    "                df = pd.DataFrame(rows, columns=columns)\n",
    "                df = df[df['Tm'] == team_id]\n",
    "                if len(df) == 0:\n",
    "                    index += 1\n",
    "                    newindex = '0' + str(index)\n",
    "                    statScraper(name, year, newindex, team_id)\n",
    "                result.close()\n",
    "                df['PlayerID'] = name[2]\n",
    "            elif x == 1:\n",
    "                columns = ['G', 'Date', 'Age', 'Tm', 'Location', 'Opp', 'GS',\n",
    "                           'Active', 'MP', 'TS%', 'eFG%', 'ORB%', 'DRB%',\n",
    "                           'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%',\n",
    "                           'USG%', 'ORtg', 'DRtg', 'GmSc', 'BPM']\n",
    "                df2 = pd.DataFrame(rows, columns=columns)\n",
    "                df2 = df2[df2['Tm'] == team_id]\n",
    "                if len(df2) == 0:\n",
    "                    index += 1\n",
    "                    newindex = '0' + str(index)\n",
    "                    statScraper(name, year, newindex, team_id)\n",
    "                result.close()\n",
    "                df2 = df2.drop(df2.columns[[0, 2, 3, 4, 5, 6, 7, 8, -2]], axis=1)\n",
    "        except:\n",
    "            print('Error Scraping' ,index)\n",
    "            index+=1\n",
    "            if index > 4:\n",
    "                print('Stat scraping failed for:', name[0], name[1])\n",
    "                print(url)\n",
    "                return None\n",
    "            newindex = '0' + str(index)\n",
    "            statScraper(name, year, newindex, team_id)\n",
    "    statdf = pd.merge(df, df2,how='outer', on='Date')\n",
    "    statdf.insert(0, 'Name', name[1] + ', ' + name[0])\n",
    "    print('Successfully Scraped:', name[0], name[1])\n",
    "    return statdf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def advancedstatScraper(name, year, playerindex, team_id):\n",
    "    index = int(playerindex)\n",
    "    lname = name[1]\n",
    "    fname = name[0]\n",
    "    lnamelist = list(lname)\n",
    "    linitial = lnamelist[0]\n",
    "    fnamelist = list(fname)\n",
    "    lname5 = ''\n",
    "    for x in range(5):\n",
    "        try:\n",
    "            lname5 += lnamelist[x]\n",
    "        except:\n",
    "            break\n",
    "    f2i = fnamelist[0] + fnamelist[1]\n",
    "    url = f'https://www.basketball-reference.com/players/{linitial}/{lname5}{f2i}{playerindex}/gamelog-advanced/{year}/'\n",
    "    print(url)\n",
    "    #try:\n",
    "    result = requests.get(url)\n",
    "    print(result.status_code)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    columns = ['G', 'Date',\t'Age', 'Tm', 'Opp', 'GS', 'MP', 'TS%', 'eFG%', 'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'ORtg', 'DRtg', 'GmSc', 'BPM', '', '']\n",
    "    table = soup.find('table', {'class': 'row_summable'})\n",
    "    trs = table.find_all('tr')\n",
    "    rows = []\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        row = [td.text.replace('\\n', '').strip() for td in tds]\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    df = df[df['Tm'] == team_id]\n",
    "    if len(df) == 0:\n",
    "        index += 1\n",
    "        newindex = '0' + str(index)\n",
    "        advancedstatScraper(name, year, newindex, team_id)\n",
    "    result.close()\n",
    "    df = df.drop(df.columns[[0, 1, 2, 3, 4, 5, 6]], axis=1)\n",
    "    return df\n",
    "    #except:\n",
    "        #index+=1\n",
    "        #if index > 4:\n",
    "            #print('Stat parsing failed for:', fname, lname)\n",
    "            #print(url)\n",
    "            #return None\n",
    "        #newindex = '0' + str(index)\n",
    "        #advancedstatScraper(name, year, newindex, team_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def urlConvertor(name, year, playerindex, advanced: bool):\n",
    "    lname = name[1]\n",
    "    fname = name[0]\n",
    "    lnamelist = list(lname)\n",
    "    linitial = lnamelist[0]\n",
    "    fnamelist = list(fname)\n",
    "    lname5 = ''\n",
    "    for x in range(5):\n",
    "        try:\n",
    "            lname5 += lnamelist[x]\n",
    "        except:\n",
    "            break\n",
    "    f2i = fnamelist[0] + fnamelist[1]\n",
    "    if advanced == False:\n",
    "        url = f'https://www.basketball-reference.com/players/{linitial}/{lname5}{f2i}{playerindex}/gamelog/{year}/'\n",
    "    else:\n",
    "        url = f'https://www.basketball-reference.com/players/{linitial}/{lname5}{f2i}{playerindex}/gamelog-advanced/{year}/'\n",
    "    return url, advanced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def concatStats(df1, df2):\n",
    "    df = df1.join(df2)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def rosterScraper(TeamID, year, id_number):\n",
    "    url = f\"https://www.basketball-reference.com/teams/{TeamID}/{year}.html\"\n",
    "    result = requests.get(url)\n",
    "    try:\n",
    "        src = result.content\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        table = soup.find('table', {'class': 'sortable'})\n",
    "        names = []\n",
    "        trs = table.find_all('tr')\n",
    "        rows = []\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                td = tr.find('td', {'data-stat': 'player'})\n",
    "                a_tag = td.find('a')\n",
    "                name = a_tag.get_text()\n",
    "                name = unidecode.unidecode(name)\n",
    "                name = re.sub(r'[^\\w\\s]','',name)\n",
    "                names.append(name)\n",
    "            except:\n",
    "                pass\n",
    "        for x in range(len(names)):\n",
    "            names[x] = names[x].split()\n",
    "            names[x].append(id_number)\n",
    "            id_number += 1\n",
    "        print(TeamID,\"roster successfully parsed\")\n",
    "        return names\n",
    "    except:\n",
    "        return False\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def nba_teams_list(year):\n",
    "    team_id = 101\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
    "    result = requests.get(url)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    table = soup.find('table', {'class': 'stats_table sortable', 'data-cols-to-freeze': ',2', 'id': 'per_game-team'})\n",
    "    teams = []\n",
    "    ids = {}\n",
    "    trs = table.find_all('tr')\n",
    "    rows = []\n",
    "    x = 0\n",
    "    for tr in trs[1:]:\n",
    "        #print(tr.prettify())\n",
    "        try:\n",
    "            td = tr.find('td', {'data-stat': 'team', 'class': 'left'})\n",
    "            a_tag = td.find('a')\n",
    "            team = a_tag.get_text()\n",
    "            teams.append(team)\n",
    "            link = a_tag.attrs['href']\n",
    "            link = list(link)\n",
    "            acronym = link[7] + link[8] + link[9]\n",
    "            ids[teams[x]] = []\n",
    "            ids[teams[x]].append(acronym)\n",
    "            x+=1\n",
    "        except:\n",
    "            pass\n",
    "    for x in range(len(teams)):\n",
    "        ids[teams[x]].append(team_id)\n",
    "        team_id+=1\n",
    "    return teams, ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def leagueRosters(year):\n",
    "    teamrosters = {}\n",
    "    id_number = 1001\n",
    "    teams, team_ids = nba_teams_list(year)\n",
    "    for team in teams:\n",
    "        teamrosters[team] = rosterScraper(team_ids[team][0], year, id_number)\n",
    "        id_number+=len(teamrosters[team])\n",
    "    return teamrosters, team_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def teamRoster(team, year):\n",
    "    roster = []\n",
    "    id_number = 1001\n",
    "    teams, team_ids = nba_teams_list(year)\n",
    "    roster = rosterScraper(team_ids[team][0], year, id_number)\n",
    "    return roster, team_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def parse_player_stats(name, team, year):\n",
    "    name = name.split()\n",
    "    name.append('1001')\n",
    "    teams, ids = nba_teams_list(year)\n",
    "    team_id = ids[team][0]\n",
    "    df = statScraper(name, year, '01', team_id)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def parse_entire_teams_stats(team, year):\n",
    "    roster, team_ids = teamRoster(team, year)\n",
    "    for x in range(len(roster)):\n",
    "        try:\n",
    "            if x == 0:\n",
    "                player = roster[x]\n",
    "                df = statScraper(player, year, '01', team_ids[team][0])\n",
    "            else:\n",
    "                player = roster[x]\n",
    "                df = df.append(statScraper(player, year, '01', team_ids[team][0]))\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def parse_entire_league_stats(year):\n",
    "    rosters, team_ids = leagueRosters(year)\n",
    "    y = 0\n",
    "    for team in rosters:\n",
    "        for x in range(len(rosters[team])):\n",
    "            try:\n",
    "                if x == 0 and y == 0:\n",
    "                    player = rosters[team][x]\n",
    "                    print(player)\n",
    "                    df = statScraper(player, year, '01', team_ids[team][0])\n",
    "                else:\n",
    "                    player = rosters[team][x]\n",
    "                    df = df.append(statScraper(player, year, '01', team_ids[team][0]))\n",
    "            except:\n",
    "                pass\n",
    "        y+=1\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def save_df(df, title):\n",
    "    df.to_csv(rf'C:\\Users\\jleus\\OneDrive\\Documents\\CSVS\\{title}.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKC roster successfully parsed\n",
      "https://www.basketball-reference.com/players/A/AldriCo01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/A/AldriCo01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Cole Aldrich\n",
      "https://www.basketball-reference.com/players/C/ColliNi01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/C/ColliNi01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Nick Collison\n",
      "https://www.basketball-reference.com/players/C/CookDa01/gamelog/2012/\n",
      "200\n",
      "Error Scraping 1\n",
      "https://www.basketball-reference.com/players/C/CookDa02/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/C/CookDa02/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Daequan Cook\n",
      "https://www.basketball-reference.com/players/C/CookDa01/gamelog-advanced/2012/\n",
      "200\n",
      "Error Scraping 2\n",
      "https://www.basketball-reference.com/players/C/CookDa03/gamelog/2012/\n",
      "200\n",
      "Error Scraping 3\n",
      "https://www.basketball-reference.com/players/C/CookDa04/gamelog/2012/\n",
      "200\n",
      "Error Scraping 4\n",
      "https://www.basketball-reference.com/players/D/DuranKe01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/D/DuranKe01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Kevin Durant\n",
      "https://www.basketball-reference.com/players/F/FisheDe01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/F/FisheDe01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Derek Fisher\n",
      "https://www.basketball-reference.com/players/H/HardeJa01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HardeJa01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: James Harden\n",
      "https://www.basketball-reference.com/players/H/HaywaLa01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/H/HaywaLa01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Lazar Hayward\n",
      "https://www.basketball-reference.com/players/I/IbakaSe01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/I/IbakaSe01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Serge Ibaka\n",
      "https://www.basketball-reference.com/players/I/IveyRo01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/I/IveyRo01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Royal Ivey\n",
      "https://www.basketball-reference.com/players/J/JacksRe01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/J/JacksRe01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Reggie Jackson\n",
      "https://www.basketball-reference.com/players/M/MaynoEr01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/M/MaynoEr01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Eric Maynor\n",
      "https://www.basketball-reference.com/players/M/MohamNa01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/M/MohamNa01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Nazr Mohammed\n",
      "https://www.basketball-reference.com/players/P/PerkiKe01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/P/PerkiKe01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Kendrick Perkins\n",
      "https://www.basketball-reference.com/players/R/ReidRy01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/R/ReidRy01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Ryan Reid\n",
      "https://www.basketball-reference.com/players/S/SefolTh01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/S/SefolTh01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Thabo Sefolosha\n",
      "https://www.basketball-reference.com/players/W/WestbRu01/gamelog/2012/\n",
      "200\n",
      "https://www.basketball-reference.com/players/W/WestbRu01/gamelog-advanced/2012/\n",
      "200\n",
      "Successfully Scraped: Russell Westbrook\n"
     ]
    }
   ],
   "source": [
    "save_df(parse_entire_teams_stats('Oklahoma City Thunder', '2012'), 'OKCStats2012')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP\n"
     ]
    }
   ],
   "source": [
    "print('STOP')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}